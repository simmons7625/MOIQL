# Configuration for Objective-Dimensional Soft Inverse Q-Learning (OD-SQIL)

# Environment settings
env_name: "mo-highway"  # "deep_sea_treasure" or "mo-highway"

# Network architecture
hidden_dim: 256
obs_dim: 25  # 25 for mo-highway (5x5 flattened), 11x11=121 for deep_sea_treasure
action_dim: 5  # 5 for mo-highway, 4 for deep_sea_treasure
n_objectives: 2  # Number of objectives in multi-objective reward

# IQL hyperparameters
lr: 0.0003  # Learning rate
gamma: 0.99  # Discount factor
tau: 0.005  # Soft update coefficient for target network
alpha: 0.2  # Temperature parameter for soft Q-learning
mismatch_coef: 1.0  # Coefficient for mismatch regularization term

# Training settings
batch_size: 256  # Batch size for updates
n_updates: 10000  # Total number of training updates
replay_buffer_size: 100000  # Size of replay buffer for storing transitions
expert_buffer_size: 50000  # Size of buffer for expert demonstrations
expert_ratio: 0.5  # Ratio of expert samples in each batch (0.0 to 1.0)

# Data collection
expert_trajectories_path: "simulation_results/trajectories.json"  # Path to expert demonstrations

# State Space Model (SSM) settings
ssm_type: "particle_filter"  # Options: "particle_filter", "ekf", "neural_ssm"

# Particle Filter settings (used if ssm_type == "particle_filter")
particle_filter:
  n_particles: 1000
  process_noise: 0.01
  observation_noise: 0.1
  initial_noise: 0.5

# Extended Kalman Filter settings (used if ssm_type == "ekf")
ekf:
  process_noise: 0.01
  observation_noise: 0.1
  initial_covariance: 1.0

# Neural SSM settings (used if ssm_type == "neural_ssm")
neural_ssm:
  hidden_dim: 64
  learning_rate: 0.001
  process_noise: 0.01
  observation_noise: 0.1

# Preference function settings (for environment wrapper)
contenous_decay: 0.01  # Linear decay rate for preference weights
init_weight: [0.8, 0.2]  # Initial weights for objectives [obj1, obj2]

# Highway-specific settings (only used if env_name == "mo-highway")
safety_distance_threshold: 10.0  # Distance threshold for safety switching
safety_boost_factor: 1.5  # Factor to boost safety weight when close to cars

# Device settings
device: "cuda"  # "cuda" or "cpu"

# Logging and saving
use_wandb: true
wandb_project: "MOIQL"
wandb_run_name: "odsqil_highway"
save_dir: "iql_results"
save_interval: 1000  # Save model every N updates
log_interval: 100  # Log metrics every N updates

# Evaluation settings
eval_interval: 500  # Evaluate every N updates
eval_episodes: 10  # Number of episodes for evaluation

# Configuration for Objective-Dimensional Soft Inverse Q-Learning (OD-SQIL)

# Expert data source
# - Environment name is auto-detected from train_dir path (dst_train -> deep_sea_treasure, highway_train -> mo-highway)
# - All environment settings are loaded from expert_dir/train_dir/config.yaml
expert_dir: "simulation_rl/dst_from_1_decay_1e-2/"
n_trajectories: 10  # Number of trajectories to use from expert dataset

# IQL training configuration
iql:
  hidden_dim: 256  # Network hidden dimension
  lr: 1.0e-6  # Learning rate for Q-network
  gamma: 0.99  # Discount factor
  tau: 0.005  # Soft update coefficient for target network
  mismatch_coef: 10.0  # Coefficient for mismatch update ratio regularization (0.0 = disable)
  weight_decay: 0.01  # Weight decay (L2 penalty) for AdamW optimizer

  n_epochs: 10000  # Total number of training epochs (batch-based training)
  batch_size: 256  # Batch size for training

# State Space Model (SSM) for preference prediction
ssm_type: "pf"  # Options: "pf" (particle filter), "ekf" (extended kalman filter), "gp" (gaussian process)

# Particle Filter settings (used if ssm_type == "pf")
pf:
  n_particles: 1000
  process_noise: 0.05
  observation_noise: 1.0 # temperature of softmax likelihood, so should be higher than 1.0

# Extended Kalman Filter settings (used if ssm_type == "ekf")
ekf:
  process_noise: 0.05
  observation_noise: 0.1
  initial_variance: 1.0e+4

# Gaussian Process SSM settings (used if ssm_type == "gp")
gp:
  length_scale: 1.0  # GP kernel length scale (controls temporal smoothness, lower = more variation)
  signal_variance: 1.0  # GP kernel signal variance (controls amplitude of variations)
  observation_noise: 0.1  # Observation noise for likelihood
  kernel_type: "rbf"  # Kernel type: "rbf" (Gaussian), "matern32", "matern52"

# Device
device: "cuda"

# Logging
use_wandb: false
wandb_project: "MOIQL"
save_dir: "moiql_results"